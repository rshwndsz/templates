{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pl_template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3ZAarhZX6bg"
      },
      "source": [
        "# PL_TEMPLATE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNJxTTxoX7oQ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSljkR8AYIit"
      },
      "source": [
        "### Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4FYNFxPXF2v"
      },
      "source": [
        "%%shell\n",
        "pip install git+https://github.com/PytorchLightning/pytorch-lightning.git@master > /dev/null 2>&1\n",
        "pip install git+https://github.com/albumentations-team/albumentations > /dev/null 2>&1\n",
        "pip install neptune-client > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs5eE9JbXNP6"
      },
      "source": [
        "# STL\n",
        "import math\n",
        "import os\n",
        "import glob\n",
        "import logging\n",
        "from getpass import getpass\n",
        "\n",
        "# Numerical Python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.data as D\n",
        "import torchvision as tv\n",
        "import pytorch_lightning as pl\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HnBYDXyxPjd"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xZIhKRLYD9-"
      },
      "source": [
        "CONSTANTS = {\n",
        "    'SEED': 81, \n",
        "    'TEST_DRIVE': True,\n",
        "\n",
        "    'NEPTUNE': {\n",
        "        'USERNAME': 'rshwndsz',\n",
        "        'PROJECT': 'template',\n",
        "        'EXPERIMENT_NAME': '',\n",
        "        'API_TOKEN': getpass('Enter your private Neptune API token: '),\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPnHeCE8X-j4"
      },
      "source": [
        "### Logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gi5nbpGXkZI"
      },
      "source": [
        "import logging\n",
        "from logging.config import dictConfig\n",
        "\n",
        "LOGGING_CONFIG = {\n",
        "    'version': 1,\n",
        "    'disable_existing_loggers': True,\n",
        "    'formatters': {\n",
        "        'standard': {\n",
        "            'format': '%(asctime)s %(filename)9s: %(levelname)8s %(message)s'\n",
        "        },\n",
        "    },\n",
        "    'handlers': {\n",
        "        'stdout': {\n",
        "            'level': 'DEBUG',\n",
        "            'formatter': 'standard',\n",
        "            'class': 'logging.StreamHandler',\n",
        "            'stream': 'ext://sys.stdout',  # Default is stderr\n",
        "        },\n",
        "        'file': {\n",
        "            'class': 'logging.handlers.RotatingFileHandler',\n",
        "            'level': 'DEBUG',\n",
        "            'formatter': 'standard',\n",
        "            'filename': '.logs/LOG.log',\n",
        "            'mode': 'a',\n",
        "            'maxBytes': 10485760,\n",
        "            'backupCount': 5,\n",
        "        }\n",
        "    },\n",
        "    'loggers': {\n",
        "        'sarcd': {\n",
        "            'handlers': ['stdout', 'file'],\n",
        "            'level': 'DEBUG',\n",
        "            'propagate': True\n",
        "        },\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "logger = logging.getLogger('sarcd')\n",
        "\n",
        "# Test drive the logger\n",
        "if CONSTANTS['TEST_DRIVE']:\n",
        "    logger.debug(f\"Torch: {torch.__version__}, \"\n",
        "                 f\"Torchvision: {tv.__version__}, \"\n",
        "                 f\"Pytorch Lightning: {pl.__version__}, \"\n",
        "                 f\"albumentations: {A.__version__}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9pIQ3CNX9lX"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FC04tuiXybH"
      },
      "source": [
        "def download_file(url, destination_dir='./', desc=None, force=False):\n",
        "    \"\"\"\n",
        "    Download a file from any url using requests\n",
        "    \"\"\"\n",
        "    # Convert path to pathlib object if not already\n",
        "    destination_dir = Path(destination_dir)\n",
        "    # Get filename from url\n",
        "    fname = url.split('/')[-1]\n",
        "    # Construct path to file in local machine\n",
        "    local_filepath = Path(destination_dir) / fname\n",
        "\n",
        "    if local_filepath.is_file() and not force:\n",
        "        logger.info(\"File(s) already downloaded. Use force=True to download again.\")\n",
        "        return local_filepath\n",
        "    else:\n",
        "        # Safely create nested directory - https://stackoverflow.com/a/273227\n",
        "        destination_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if desc is None:\n",
        "        desc = f\"Downloading {fname}\"\n",
        "\n",
        "    # Download large file with requests - https://stackoverflow.com/a/16696317\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        total_size_in_bytes = int(r.headers.get('content-length', 0))\n",
        "        block_size          = 1024\n",
        "        # Progress bar for downloading file - https://stackoverflow.com/a/37573701\n",
        "        pbar = tqdm(total=total_size_in_bytes, \n",
        "                    unit='iB', \n",
        "                    unit_scale=True,\n",
        "                    desc=desc)\n",
        "        with open(local_filepath, 'wb') as f:\n",
        "            for data in r.iter_content(block_size):\n",
        "                pbar.update(len(data))\n",
        "                f.write(data)\n",
        "        pbar.close()\n",
        "    return local_filepath\n",
        "\n",
        "\n",
        "def extract_file(fname, ftype=None, destination_dir=\"./\", desc=None, remove_extract=False):\n",
        "    # Convert to pathlib objects\n",
        "    fname = Path(fname)\n",
        "    destination_dir = Path(destination_dir)\n",
        "\n",
        "    # Check arguments\n",
        "    if not fname.is_file():\n",
        "        raise IOError(f\"The file {str(fname)} does not exist.\")\n",
        "    \n",
        "    # Safely create nested directory - https://stackoverflow.com/a/273227\n",
        "    destination_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if desc is None:\n",
        "        desc = f\"Extracting {str(fname.name)}\"\n",
        "\n",
        "    # Get type of extract\n",
        "    if ftype is None:\n",
        "        ftype = fname.suffix\n",
        "\n",
        "    # Extract the dataset into `destination_dir`\n",
        "    if ftype == '.tar':\n",
        "        with tarfile.open(fname) as tar:\n",
        "            pbar = tqdm(iterable=tar.getmembers(), total=len(tar.getmembers()), desc=desc)\n",
        "            # Extract files with progress bar - https://stackoverflow.com/a/53405055\n",
        "            for member in pbar:\n",
        "                tar.extract(member=member, path=destination_dir)\n",
        "\n",
        "    elif ftype == '.zip':\n",
        "        # https://stackoverflow.com/a/56970565\n",
        "        with ZipFile(fname, 'r') as zip:\n",
        "            pbar = tqdm(zip.infolist(), desc=desc)\n",
        "            for member in pbar:\n",
        "                zip.extract(member, destination_dir)\n",
        "\n",
        "    else:\n",
        "        raise IOError(f\"The suffix: {ftype} is not supported.\")\n",
        "            \n",
        "    if remove_extract:\n",
        "        # Delete the compressed dataset\n",
        "        os.remove(fname)   \n",
        "\n",
        "\n",
        "def make_grid(tensors, nrow=2, padding=2, isNormalized=True):\n",
        "    \"\"\"\n",
        "    Convert a list of tensors into a numpy image grid\n",
        "    \"\"\"\n",
        "    grid = tv.utils.make_grid(tensor=tensors.detach().cpu(), \n",
        "                              nrow=nrow, \n",
        "                              padding=padding, \n",
        "                              normalize= (not isNormalized))\n",
        "    if isNormalized:\n",
        "        ndgrid = grid.mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).numpy().astype(np.uint16)\n",
        "    else:\n",
        "        ndgrid = grid.clamp_(0, 255).permute(1, 2, 0).numpy().astype(np.uint16)\n",
        "    return ndgrid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-xIcmFTYSmn"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuxgRWpWYSGs"
      },
      "source": [
        "class GenericImageDS(D.Dataset):\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_glob=\"*.jpg\",\n",
        "                 train=True,\n",
        "                 transform=None,\n",
        "                 min_image_dim=256):\n",
        "        self.root = root\n",
        "        self.image_glob = image_glob\n",
        "        self.train = train\n",
        "        self.min_image_dim = min_image_dim\n",
        "\n",
        "        image_regex = os.path.join(self.root, self.image_glob)\n",
        "        self.image_paths = glob.glob(image_regex)\n",
        "        if not len(self.image_paths):\n",
        "            raise ValueError(f\"No image found using {image_regex}\")\n",
        "\n",
        "        self.transform = transform\n",
        "        # Default set of transforms if none are provided\n",
        "        if self.transform is None:\n",
        "            self.transform = A.Compose([\n",
        "                A.Resize(self.min_image_dim, self.min_image_dim, 4, True, 1),\n",
        "                A.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), p=1),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "        logger.info(f\"Total samples: {len(self.image_paths)}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def download(urls, destination_dir, force=False):\n",
        "        destination_dir = Path(destination_dir)\n",
        "\n",
        "        # Check validity of arguments\n",
        "        if not destination_dir.is_dir():\n",
        "            raise ValueError(\"Provide destination_dir\")\n",
        "        if urls is None:\n",
        "            raise ValueError(\"Provide URL(s)\")\n",
        "\n",
        "        # Download & Extract\n",
        "        for url in urls:\n",
        "            fname = download_file(url, destination_dir)\n",
        "            extract_file(fname, destination_dir)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        image = np.asarray(Image.open(image_path))\n",
        "        image = self.transform(image=image)[\"image\"]\n",
        "        return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-nvg48JYlhF"
      },
      "source": [
        "# Test drive the dataset API\n",
        "if CONSTANTS['TEST_DRIVE']:\n",
        "    train_transform = A.Compose([\n",
        "        A.VerticalFlip(p=0.1),\n",
        "        A.HorizontalFlip(p=0.6),\n",
        "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=1),\n",
        "        A.Resize(256, 256, interpolation=INTER_LANCZOS4, p=1),\n",
        "        A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=1),\n",
        "        A.MotionBlur(p=1),\n",
        "        A.RandomBrightnessContrast(p=1),\n",
        "        A.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), p=1),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "    ds = ZeroDceDS(\"data/train_data/\", \"*.jpg\", train=True, transform=train_transform)\n",
        "    dl = D.DataLoader(ds, batch_size=8, pin_memory=False, shuffle=False)\n",
        "\n",
        "    batch = next(iter(dl))\n",
        "    logger.debug(f\"{batch[3].max(), batch[3].min()}\")\n",
        "    \n",
        "    plt.imshow(batch[3].permute(1, 2, 0))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PzQKbuNaQy-"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rIkYigHYoPF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxDswRI8aSx4"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoDEdoY0aR6A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwmGy6RSaYzx"
      },
      "source": [
        "## Lightning Module ü™Ñ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57jkQ5F5aVs_"
      },
      "source": [
        "class FinalNet(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super(FinalNet, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO\n",
        "        return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), \n",
        "                                lr=self.hparams['lr'], \n",
        "                                weight_decay=self.hparams['weight_decay'])\n",
        "\n",
        "    def loss_function(self, inputs, outputs):\n",
        "        # TODO\n",
        "        return outputs\n",
        "\n",
        "    def prepare_data(self):\n",
        "        train_transform = A.Compose([\n",
        "            A.VerticalFlip(p=0.1),\n",
        "            A.HorizontalFlip(p=0.6),\n",
        "            A.Resize(self.hparams['image_size'], self.hparams['image_size'], interpolation=4, p=1),\n",
        "            A.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), p=1),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "        test_transform = A.Compose([\n",
        "            A.Resize(self.hparams['image_size'], self.hparams['image_size'], interpolation=4, p=1),\n",
        "            A.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), p=1),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "        self.train_ds = ZeroDceDS(\"data/train_data/\",    \"*.jpg\", train=True,  transform=train_transform)\n",
        "        self.val_ds   = ZeroDceDS(\"data/test_data/DICM\", \"*.jpg\", train=False, transform=test_transform)\n",
        "        self.test_ds  = ZeroDceDS(\"data/test_data/LIME\", \"*.bmp\", train=False, transform=test_transform)\n",
        "                  \n",
        "    def train_dataloader(self):\n",
        "        return D.DataLoader(self.train_ds, \n",
        "                            batch_size=self.hparams['batch_size']['train'], \n",
        "                            num_workers=4, \n",
        "                            pin_memory=True, \n",
        "                            shuffle=True)\n",
        "        \n",
        "    def val_dataloader(self):\n",
        "        return D.DataLoader(self.val_ds, \n",
        "                            batch_size=self.hparams['batch_size']['val'],\n",
        "                            num_workers=4, \n",
        "                            pin_memory=True, \n",
        "                            shuffle=False)\n",
        "        \n",
        "    def test_dataloader(self):\n",
        "        return D.DataLoader(self.test_ds,\n",
        "                            batch_size=self.hparams['batch_size']['test'],\n",
        "                            num_workers=4, \n",
        "                            pin_memory=True, \n",
        "                            shuffle=False)\n",
        "        \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images = batch\n",
        "        outputs = self(images)\n",
        "        loss = self.loss_function(images, outputs)\n",
        "\n",
        "        self.logger.experiment.log_metric('step_train_loss', loss)\n",
        "        return { 'loss': loss }\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
        "        self.logger.experiment.log_metric('epoch_train_loss', avg_loss)\n",
        "        \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images = batch\n",
        "        outputs = self(images)\n",
        "        loss = self.loss_function(images, enhanced, A)\n",
        "\n",
        "        self.logger.experiment.log_metric('step_val_loss', loss)\n",
        "        return {'val_loss': loss, 'outputs': outputs}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_val_loss = torch.stack([output['val_loss'] for output in outputs]).mean()\n",
        "        self.log('avg_val_loss', avg_val_loss)\n",
        "        self.logger.experiment.log_metric('epoch_val_loss', avg_val_loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        inputs = batch\n",
        "        outputs = self(inputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdb6OMKha1N3"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-h2wDvKa6jQ"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvUXgrOha0op"
      },
      "source": [
        "hparams = {\n",
        "    'lr': 0.0001, \n",
        "    'weight_decay': 0.0001,\n",
        "    'batch_size': {\n",
        "        'train': 8,\n",
        "        'val': 4,\n",
        "        'test': 4,\n",
        "    },\n",
        "    'image_size': 256,\n",
        "    'gradient_clip_val': 0.1, \n",
        "    'max_epochs': 200,\n",
        "    'min_epochs': 10,\n",
        "    'check_val_every_n_epoch': 4,\n",
        "    'precision': 32,     # https://pytorch-lightning.readthedocs.io/en/latest/amp.html\n",
        "    'benchmark': True,\n",
        "    'deterministic': False,\n",
        "    'use_gpu': torch.cuda.is_available(),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR-mWHfha4Kg"
      },
      "source": [
        "### Bells & whistles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-53FRnJxa3b8"
      },
      "source": [
        "# https://pytorch-lightning.readthedocs.io/en/latest/weights_loading.html?highlight=ModelCheckpoint\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "model_checkpoint = ModelCheckpoint(filepath   = 'checkpoints/{epoch:04d}-{epoch_val_loss:.3f}.ckpt',\n",
        "                                   save_top_k = 5,\n",
        "                                   monitor    = 'val_loss',\n",
        "                                   mode       = 'min',\n",
        "                                   period     = 5)\n",
        "\n",
        "# https://pytorch-lightning.readthedocs.io/en/latest/early_stopping.html\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "early_stop_callback = EarlyStopping(\n",
        "   monitor   = 'epoch_val_loss',\n",
        "   min_delta = 0.00,\n",
        "   patience  = 3,\n",
        "   verbose   = True,\n",
        "   mode      = 'min'\n",
        ")\n",
        "\n",
        "if not CONSTANT['TEST_DRIVE']:\n",
        "    # https://docs.neptune.ai/api-reference/neptune/experiments/index.html#neptune.experiments.Experiment\n",
        "    from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
        "    pl_logger = NeptuneLogger(\n",
        "        api_key         = CONSTANTS['NEPTUNE']['API_TOKEN'],\n",
        "        project_name    = f\"{CONSTANTS['NEPTUNE']['USERNAME']}/{CONSTANTS['NEPTUNE']['PROJECT']}\",\n",
        "        close_after_fit = False,\n",
        "        experiment_name = CONSTANTS['NEPTUNE']['EXPERIMENT_NAME'],\n",
        "        params          = hparams,\n",
        "    )\n",
        "else:\n",
        "    # https://pytorch-lightning.readthedocs.io/en/1.0.8/logging.html\n",
        "    from pytorch_lightning.loggers import TensorBoardLogger\n",
        "    pl_logger = TensorBoardLogger('tensorboard-logs/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oi_vqv6x7BD"
      },
      "source": [
        "### Instantiations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9yuf8HGa8E8"
      },
      "source": [
        "logger.setLevel(logging.INFO)\n",
        "pl.seed_everything(CONSTANTS['SEED'])\n",
        "\n",
        "model   = FinalNet(hparams=hparams)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus                    = -1 if hparams['use_gpu'] else 0,\n",
        "    precision               = hparams['precision'],\n",
        "    gradient_clip_val       = hparams['gradient_clip_val'],\n",
        "    benchmark               = hparams['benchmark'],\n",
        "    deterministic           = hparams['deterministic'],\n",
        "    max_epochs              = hparams['max_epochs'],\n",
        "    min_epochs              = hparams['min_epochs'],\n",
        "    check_val_every_n_epoch = hparams['check_val_every_n_epoch'],\n",
        "    logger                  = pl_logger,\n",
        "    checkpoint_callback     = model_checkpoint,\n",
        "    callbacks               = [early_stop_callback],\n",
        ") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8968ANG9bR1G"
      },
      "source": [
        "### Train üêâüêâ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qnj1zATbRcz"
      },
      "source": [
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nKV4JG7bVKc"
      },
      "source": [
        "if not CONSTANTS['TEST_DRIVE']:\n",
        "    # Log model summary\n",
        "    for chunk in [x for x in str(model).split('\\n')]:\n",
        "        neptune_logger.experiment.log_text('model_summary', str(chunk))\n",
        "\n",
        "    # Which GPUs where used?\n",
        "    gpu_list = [f'{i}:{torch.cuda.get_device_name(i)}' for i in range(torch.cuda.device_count())] \n",
        "    neptune_logger.experiment.log_text('GPUs used', ', '.join(gpu_list))\n",
        "\n",
        "    # Log best 3 model checkpoints to Neptune\n",
        "    for k in model_checkpoint.best_k_models.keys():\n",
        "        model_name = 'checkpoints/' + k.split('/')[-1]\n",
        "        neptune_logger.experiment.log_artifact(k, model_name)\n",
        "\n",
        "    # Save last path\n",
        "    last_model_path = f\"checkpoints/last_model--epoch={trainer.current_epoch}.ckpt\"\n",
        "    trainer.save_checkpoint(last_model_path)\n",
        "    neptune_logger.experiment.log_artifact(last_model_path, 'checkpoints/' + last_model_path.split('/')[-1])\n",
        "\n",
        "    # Log score of the best model checkpoint\n",
        "    neptune_logger.experiment.set_property('best_model_score', model_checkpoint.best_model_score.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ0TkMMwc0B4"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr09rYy0c1MU"
      },
      "source": [
        "trainer.test()\n",
        "\n",
        "if not CONSTANTS['TEST_DRIVE']:\n",
        "    # Stop Neptune Logger\n",
        "    neptune_logger.experiment.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0hfgUpGc8KY"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loFyeV9QdAMG"
      },
      "source": [
        "### Get weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPgTX3xoc9mH"
      },
      "source": [
        "# Get Neptune API token\n",
        "from getpass import getpass\n",
        "api_token = getpass(\"Enter Neptune.ai API token: \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBsssHUVc-_H"
      },
      "source": [
        "# Initialize Neptune project\n",
        "import neptune\n",
        "from neptune import Session\n",
        "\n",
        "session = Session.with_default_backend(api_token=api_token)\n",
        "project = session.get_project('rshwndsz/nightsight')\n",
        "experiment = project.get_experiments(id='NIG-11')[0]\n",
        "experiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Tl1389dDnu"
      },
      "source": [
        "# Download checkpoint from Neptune\n",
        "artifact_path   = 'epoch=133-avg_val_loss=1.06.ckpt'\n",
        "artifact_name   = artifact_path.split('/')[-1]\n",
        "checkpoint_dir  = os.path.join('checkpoints', 'downloads')\n",
        "checkpoint_path = os.path.join(checkpoint_dir, artifact_name)\n",
        "\n",
        "experiment.download_artifact(path=artifact_path, destination_dir=checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep_t3K3QdOf8"
      },
      "source": [
        "### Load weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK0SBDmudNma"
      },
      "source": [
        "testing_model = FinalNet.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
        "testing_model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbQiVlludLp7"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r8XHFogdMKq"
      },
      "source": [
        "test_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(hparams['image_size'], hparams['image_size'], interpolation=INTER_LANCZOS4, p=1),\n",
        "        A.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), p=1),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "ds = ZeroDceDS(\"data/test_data/Adobe-5k\", \"*.jpg\", train=False, transform=test_transform)\n",
        "dl = D.DataLoader(ds, batch_size=5, pin_memory=False, shuffle=True)\n",
        "batch = next(iter(dl))\n",
        "plt.imshow(batch[0].permute(1, 2, 0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}