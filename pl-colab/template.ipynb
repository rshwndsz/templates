{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.1 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/rshwndsz/templates/blob/master/pl-colab/template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PL_TEMPLATE"
      ],
      "metadata": {
        "id": "t3ZAarhZX6bg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "iNJxTTxoX7oQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Uncomment for TPU\n",
        "# !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl > /dev/null 2>&1\n",
        "!pip install pytorch-lightning --upgrade       > /dev/null 2>&1\n",
        "!pip install torchmetrics                      > /dev/null 2>&1\n",
        "!pip install lightning-bolts                   > /dev/null 2>&1\n",
        "!pip install thop                              > /dev/null 2>&1\n",
        "!pip install torchinfo                         > /dev/null 2>&1\n",
        "!pip install optuna                            > /dev/null 2>&1\n",
        "\n",
        "# Uncomment after https://github.com/neptune-ai/neptune-pytorch-lightning/issues/3 is resolved\n",
        "# !pip install neptune-client[pytorch-lightning] > /dev/null 2>&1\n",
        "!python -m pip install git+https://github.com/rshwndsz/neptune-pytorch-lightning.git@rsd/NPT-PL-3-use-existing-run > /dev/null 2>&1\n",
        "\n",
        "# Uncomment after https://github.com/neptune-ai/neptune-optuna/issues/6 is resolved\n",
        "# !pip install neptune-client[optuna]            > /dev/null 2>&1\n",
        "!python -m pip install git+https://github.com/rshwndsz/neptune-optuna.git@rsd/NPT-OPT-2-multi-objective-support > /dev/null 2>&1"
      ],
      "outputs": [],
      "metadata": {
        "id": "a4FYNFxPXF2v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# STL\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import logging\n",
        "import getpass\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "import json\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "from collections import OrderedDict\n",
        "from argparse import Namespace\n",
        "\n",
        "# Numerical Python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Image processing\n",
        "from PIL import Image\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as D\n",
        "import torchvision as tv\n",
        "import torchvision.transforms as tf\n",
        "import torchvision.transforms.functional as tff\n",
        "import torchmetrics as M\n",
        "import pytorch_lightning as pl\n",
        "import neptune.new as neptune\n",
        "import optuna\n",
        "import torchinfo\n",
        "import thop\n",
        "\n",
        "# Bells & Whistles\n",
        "from neptune.new.types import File\n",
        "from neptune.new.integrations.optuna import (NeptuneCallback, \n",
        "                                             log_study_metadata, \n",
        "                                             load_study_from_run)\n",
        "from neptune.new.integrations.pytorch_lightning import NeptuneLogger\n",
        "\n",
        "from pl_bolts.datamodules import CIFAR10DataModule\n",
        "from pytorch_lightning.callbacks import (ModelCheckpoint, \n",
        "                                         EarlyStopping)\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Misc\n",
        "import gdown\n",
        "from tqdm.notebook import tqdm"
      ],
      "outputs": [],
      "metadata": {
        "id": "fs5eE9JbXNP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Set up logging to file\n",
        "# https://stackoverflow.com/a/23681578\n",
        "\n",
        "logging.basicConfig(\n",
        "     filename='LOG.log',\n",
        "     level=logging.INFO, \n",
        "     format= '[%(asctime)s] %(levelname)8s - %(funcName)8s() - %(message)s',\n",
        "     datefmt='%H:%M:%S'\n",
        " )\n",
        "\n",
        "# Set up logging to console\n",
        "console = logging.StreamHandler()\n",
        "console.setLevel(logging.DEBUG)\n",
        "\n",
        "# Set a format which is simpler for console use\n",
        "formatter = logging.Formatter('%(levelname)8s - %(funcName)14s() - %(message)s')\n",
        "console.setFormatter(formatter)\n",
        "\n",
        "# Add the handler to the root logger\n",
        "logging.getLogger('').addHandler(console)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Test drive the logger\n",
        "logger.info(f\"\"\"\n",
        "            Torch: {torch.__version__}\n",
        "            Torchvision: {tv.__version__}\n",
        "            Pytorch Lightning: {pl.__version__} \n",
        "            Albumentations: {A.__version__}\n",
        "            \"\"\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "4Gi5nbpGXkZI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import getpass \n",
        "\n",
        "\n",
        "CONSTANTS = {\n",
        "    'API_TOKEN': getpass.getpass(prompt=\"Neptune API Token: \"),\n",
        "    'SEED': 1337,\n",
        "}\n",
        "\n",
        "pl.seed_everything(CONSTANTS['SEED'])\n",
        "os.environ[\"NEPTUNE_API_TOKEN\"] = CONSTANTS[\"API_TOKEN\"]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "i-xIcmFTYSmn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "nuxgRWpWYSGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Model"
      ],
      "metadata": {
        "id": "VBxTMxZ9cs3K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "63_8iSRzcs3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Module"
      ],
      "metadata": {
        "id": "xwmGy6RSaYzx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Sample data module\n",
        "class ImageNet(pl.LightningDataModule):\n",
        "    def __init__(self, batch_size=4, patch_size=11):\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"\n",
        "        For operations that might write to disk or \n",
        "        that need to be done only from a single process in distributed settings.\n",
        "        DO NOT use to assign state as it is called from a single process.\n",
        "        \"\"\"\n",
        "        URL    = \"\"\n",
        "        outdir = Path(\"./data/\")\n",
        "\n",
        "        # Safely create nested directory\n",
        "        outdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Download dataset\n",
        "        if not (outdir / \"dataset.mat\").exists():\n",
        "            gdown.download(URL, str(outdir / \"dataset.mat\"), quiet=False)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"For data operations on every GPU.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        pass\n",
        "        \n",
        "    def val_dataloader(self):\n",
        "        pass\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        pass\n",
        "\n",
        "    def teardown(self, stage=None):\n",
        "        \"\"\"Used to clean-up when run is finished\"\"\"\n",
        "    \n",
        "    def visualize(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "# Test\n",
        "logger.setLevel(logging.DEBUG)\n",
        "# Write testing code here\n",
        "logger.setLevel(logging.INFO)"
      ],
      "outputs": [],
      "metadata": {
        "id": "OpgZFC7KgI2N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class FinalNet(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super(FinalNet, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def loss_function(self, preds, targets):\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "                  \n",
        "    def train_dataloader(self):\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def val_dataloader(self):\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, targets = batch\n",
        "        preds = self(inputs)\n",
        "        loss  = self.loss_function(preds, targets)\n",
        "\n",
        "        self.logger.experiment.log_metric('step_train_loss', loss)\n",
        "        return { 'loss': loss }\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
        "\n",
        "        self.logger.experiment.log_metric('epoch_train_loss', avg_loss)\n",
        "        \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        inputs, targets = batch\n",
        "        preds = self(inputs)\n",
        "        loss = self.loss_function(preds, targets)\n",
        "\n",
        "        self.logger.experiment.log_metric('step_val_loss', loss)\n",
        "        return { 'val_loss': loss }\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_val_loss = torch.stack([output['val_loss'] for output in outputs]).mean()\n",
        "\n",
        "        self.log('avg_val_loss', avg_val_loss)\n",
        "        self.logger.experiment.log_metric('epoch_val_loss', avg_val_loss)\n",
        "\n",
        "\n",
        "# Test\n",
        "logger.setLevel(logging.DEBUG)\n",
        "# Write testing code here\n",
        "logger.setLevel(logging.INFO)"
      ],
      "outputs": [],
      "metadata": {
        "id": "57jkQ5F5aVs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training"
      ],
      "metadata": {
        "id": "Bdb6OMKha1N3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "hparams = {\n",
        "    'lr': 0.0001, \n",
        "    'batch_size': 4,\n",
        "    'max_epochs': 200,\n",
        "    'min_epochs': 10,\n",
        "    'check_val_every_n_epoch': 4,\n",
        "    'precision': 32,     # https://pytorch-lightning.readthedocs.io/en/latest/amp.html\n",
        "    'benchmark': True,\n",
        "    'deterministic': False,\n",
        "    'use_gpu': torch.cuda.is_available(),\n",
        "}"
      ],
      "outputs": [],
      "metadata": {
        "id": "XvUXgrOha0op"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# https://pytorch-lightning.readthedocs.io/en/latest/weights_loading.html?highlight=ModelCheckpoint\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    dirpath    = \"./checkpoints/\",\n",
        "    filename   = '{epoch:03d}__{avg_val_loss:.5f}',\n",
        "    save_top_k = 5,\n",
        "    monitor    = 'avg_val_loss',\n",
        "    mode       = 'min',\n",
        "    period     = 5\n",
        ")\n",
        "\n",
        "# https://pytorch-lightning.readthedocs.io/en/latest/early_stopping.html\n",
        "early_stop_callback = EarlyStopping(\n",
        "   monitor   = 'avg_val_loss',\n",
        "   min_delta = 1e-7,\n",
        "   patience  = 3,\n",
        "   verbose   = True,\n",
        "   mode      = 'min'\n",
        ")\n",
        "\n",
        "# https://docs.neptune.ai/api-reference/neptune/experiments/index.html#neptune.experiments.Experiment\n",
        "pl_logger = NeptuneLogger(\n",
        "    api_key         = CONSTANTS['API_TOKEN'],\n",
        "    project_name    = f\"\", # TODO\n",
        "    close_after_fit = True,\n",
        "    experiment_name = '',  # TODO\n",
        "    params          = hparams,\n",
        "    offline_model   = True,  # Comment to log into neptune.ai\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "-53FRnJxa3b8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "logger.setLevel(logging.INFO)\n",
        "pl.seed_everything(CONSTANTS['SEED'])\n",
        "\n",
        "dataset = Houston18DataModule(batch_size=hparams['batch_size'], \n",
        "                              patch_size=hparams['patch_size'])\n",
        "\n",
        "model   = FinalNet(hparams=hparams)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus                    = -1 if hparams['use_gpu'] else 0,\n",
        "    precision               = hparams['precision'],\n",
        "    gradient_clip_val       = hparams['gradient_clip_val'],\n",
        "    benchmark               = hparams['benchmark'],\n",
        "    deterministic           = hparams['deterministic'],\n",
        "    max_epochs              = hparams['max_epochs'],\n",
        "    min_epochs              = hparams['min_epochs'],\n",
        "    check_val_every_n_epoch = hparams['check_val_every_n_epoch'],\n",
        "    logger                  = pl_logger,\n",
        "    checkpoint_callback     = model_checkpoint,\n",
        "    callbacks               = [early_stop_callback],\n",
        ") "
      ],
      "outputs": [],
      "metadata": {
        "id": "V9yuf8HGa8E8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# üêâ\n",
        "trainer.fit(model, dataset)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2Qnj1zATbRcz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Log model summary\n",
        "for chunk in [x for x in str(model).split('\\n')]:\n",
        "    neptune_logger.experiment.log_text('model_summary', str(chunk))\n",
        "\n",
        "# Which GPUs where used?\n",
        "gpu_list = [f'{i}:{torch.cuda.get_device_name(i)}' \n",
        "            for i in range(torch.cuda.device_count())] \n",
        "neptune_logger.experiment.log_text('GPUs used', ', '.join(gpu_list))\n",
        "\n",
        "# Log best 3 model checkpoints to Neptune\n",
        "for k in model_checkpoint.best_k_models.keys():\n",
        "    model_name = 'checkpoints/' + k.split('/')[-1]\n",
        "    neptune_logger.experiment.log_artifact(k, model_name)\n",
        "\n",
        "# Save last path\n",
        "last_model_path = f\"checkpoints/last_model--epoch={trainer.current_epoch}.ckpt\"\n",
        "trainer.save_checkpoint(last_model_path)\n",
        "neptune_logger.experiment.log_artifact(\n",
        "    last_model_path, \n",
        "    'checkpoints/' + last_model_path.split('/')[-1]\n",
        ")\n",
        "\n",
        "# Log score of the best model checkpoint\n",
        "neptune_logger.experiment.set_property(\n",
        "    'best_model_score', \n",
        "    model_checkpoint.best_model_score.tolist()\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "9nKV4JG7bVKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "t0hfgUpGc8KY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get weights"
      ],
      "metadata": {
        "id": "loFyeV9QdAMG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Get Neptune API token\n",
        "from getpass import getpass\n",
        "api_token = getpass(\"Enter Neptune.ai API token: \")"
      ],
      "outputs": [],
      "metadata": {
        "id": "VPgTX3xoc9mH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Initialize Neptune project\n",
        "import neptune\n",
        "from neptune import Session\n",
        "\n",
        "session = Session.with_default_backend(api_token=api_token)\n",
        "project = session.get_project(f\"\") # TODO\n",
        "experiment = project.get_experiments(id='')[0] # TODO\n",
        "experiment"
      ],
      "outputs": [],
      "metadata": {
        "id": "MBsssHUVc-_H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Download checkpoint from Neptune\n",
        "artifact_path   = 'epoch=133-avg_val_loss=1.06.ckpt'\n",
        "artifact_name   = artifact_path.split('/')[-1]\n",
        "checkpoint_dir  = os.path.join('checkpoints', 'downloads')\n",
        "checkpoint_path = os.path.join(checkpoint_dir, artifact_name)\n",
        "\n",
        "experiment.download_artifact(path=artifact_path, destination_dir=checkpoint_dir)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q0Tl1389dDnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load weights"
      ],
      "metadata": {
        "id": "Ep_t3K3QdOf8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = FinalNet.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
        "model.eval()"
      ],
      "outputs": [],
      "metadata": {
        "id": "pK0SBDmudNma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "dbQiVlludLp7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# TODO"
      ],
      "outputs": [],
      "metadata": {
        "id": "9r8XHFogdMKq"
      }
    }
  ]
}