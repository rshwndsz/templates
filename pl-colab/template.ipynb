{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.1 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rshwndsz/templates/blob/master/pl-colab/template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3ZAarhZX6bg"
      },
      "source": [
        "# PL_TEMPLATE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNJxTTxoX7oQ"
      },
      "source": [
        "## 0a. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4FYNFxPXF2v"
      },
      "source": [
        "%%shell\n",
        "pip install pytorch-lightning > /dev/null 2>&1\n",
        "pip install neptune-client    > /dev/null 2>&1\n",
        "pip install torchmetrics      > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs5eE9JbXNP6"
      },
      "source": [
        "# STL\n",
        "import math\n",
        "import os\n",
        "import glob\n",
        "import logging\n",
        "import getpass\n",
        "from pathlib import Path\n",
        "\n",
        "# Numerical Python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Image processing\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.data as D\n",
        "import torchvision as tv\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# Bells & Whistles\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
        "from pytorch_lightning.callbacks import (ModelCheckpoint,\n",
        "                                         EarlyStopping)\n",
        "\n",
        "# Misc\n",
        "from tqdm.notebook import tqdm\n",
        "import gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gi5nbpGXkZI"
      },
      "source": [
        "# Set up logging to file\n",
        "# https://stackoverflow.com/a/23681578\n",
        "\n",
        "logging.basicConfig(\n",
        "     filename='LOG.log',\n",
        "     level=logging.INFO, \n",
        "     format= '[%(asctime)s] %(levelname)8s - %(funcName)8s() - %(message)s',\n",
        "     datefmt='%H:%M:%S'\n",
        " )\n",
        "\n",
        "# Set up logging to console\n",
        "console = logging.StreamHandler()\n",
        "console.setLevel(logging.DEBUG)\n",
        "\n",
        "# Set a format which is simpler for console use\n",
        "formatter = logging.Formatter('%(levelname)8s - %(funcName)14s() - %(message)s')\n",
        "console.setFormatter(formatter)\n",
        "\n",
        "# Add the handler to the root logger\n",
        "logging.getLogger('').addHandler(console)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Test drive the logger\n",
        "logger.info(f\"\"\"\n",
        "            Torch: {torch.__version__}\n",
        "            Torchvision: {tv.__version__}\n",
        "            Pytorch Lightning: {pl.__version__} \n",
        "            Albumentations: {A.__version__}\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9pIQ3CNX9lX"
      },
      "source": [
        "## 0b. Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FC04tuiXybH"
      },
      "source": [
        "def download_file(url, \n",
        "                  destination_dir='./', \n",
        "                  desc=None, \n",
        "                  force=False):\n",
        "    \"\"\"Download a file from any url using requests\"\"\"\n",
        "    # Convert path to pathlib object if not already\n",
        "    destination_dir = Path(destination_dir)\n",
        "    # Get filename from url\n",
        "    fname = url.split('/')[-1]\n",
        "    # Construct path to file in local machine\n",
        "    local_filepath = Path(destination_dir) / fname\n",
        "\n",
        "    if local_filepath.is_file() and not force:\n",
        "        logger.info(\"File(s) already downloaded. Use force=True to download again.\")\n",
        "        return local_filepath\n",
        "    else:\n",
        "        # Safely create nested directory - https://stackoverflow.com/a/273227\n",
        "        destination_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if desc is None:\n",
        "        desc = f\"Downloading {fname}\"\n",
        "\n",
        "    # Download large file with requests - https://stackoverflow.com/a/16696317\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        total_size_in_bytes = int(r.headers.get('content-length', 0))\n",
        "        block_size          = 1024\n",
        "        # Progress bar for downloading file - https://stackoverflow.com/a/37573701\n",
        "        pbar = tqdm(total=total_size_in_bytes, \n",
        "                    unit='iB', \n",
        "                    unit_scale=True,\n",
        "                    desc=desc)\n",
        "        with open(local_filepath, 'wb') as f:\n",
        "            for data in r.iter_content(block_size):\n",
        "                pbar.update(len(data))\n",
        "                f.write(data)\n",
        "        pbar.close()\n",
        "    return local_filepath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_wOS3sielDB"
      },
      "source": [
        "def extract_file(fname, \n",
        "                 ftype=None, \n",
        "                 destination_dir=\"./\", \n",
        "                 desc=None, \n",
        "                 remove_extract=False):\n",
        "    # Convert to pathlib objects\n",
        "    fname = Path(fname)\n",
        "    destination_dir = Path(destination_dir)\n",
        "\n",
        "    # Check arguments\n",
        "    if not fname.is_file():\n",
        "        raise IOError(f\"The file {str(fname)} does not exist.\")\n",
        "    \n",
        "    # Safely create nested directory - https://stackoverflow.com/a/273227\n",
        "    destination_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if desc is None:\n",
        "        desc = f\"Extracting {str(fname.name)}\"\n",
        "\n",
        "    # Get type of extract\n",
        "    if ftype is None:\n",
        "        ftype = fname.suffix\n",
        "\n",
        "    # Extract the dataset into `destination_dir`\n",
        "    if ftype == '.tar':\n",
        "        with tarfile.open(fname) as tar:\n",
        "            pbar = tqdm(\n",
        "                iterable=tar.getmembers(), \n",
        "                total=len(tar.getmembers()), \n",
        "                desc=desc\n",
        "            )\n",
        "            # Extract files with progress bar - https://stackoverflow.com/a/53405055\n",
        "            for member in pbar:\n",
        "                tar.extract(member=member, path=destination_dir)\n",
        "\n",
        "    elif ftype == '.zip':\n",
        "        # https://stackoverflow.com/a/56970565\n",
        "        with ZipFile(fname, 'r') as zip:\n",
        "            pbar = tqdm(zip.infolist(), desc=desc)\n",
        "            for member in pbar:\n",
        "                zip.extract(member, destination_dir)\n",
        "\n",
        "    else:\n",
        "        raise IOError(f\"The suffix: {ftype} is not supported.\")\n",
        "            \n",
        "    if remove_extract:\n",
        "        # Delete the compressed dataset\n",
        "        os.remove(fname)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoSQo4Boem-r"
      },
      "source": [
        "def make_grid(tensors, \n",
        "              nrow=2, \n",
        "              padding=2, \n",
        "              isNormalized=True):\n",
        "    \"\"\"Convert a list of tensors into a numpy image grid\"\"\"\n",
        "    grid = tv.utils.make_grid(tensor=tensors.detach().cpu(), \n",
        "                              nrow=nrow, \n",
        "                              padding=padding, \n",
        "                              normalize= (not isNormalized))\n",
        "    if isNormalized:\n",
        "        ndgrid = grid.mul(255) \\\n",
        "                     .add_(0.5) \\\n",
        "                     .clamp_(0, 255) \\\n",
        "                     .permute(1, 2, 0) \\\n",
        "                     .numpy() \\\n",
        "                     .astype(np.uint16)\n",
        "    else:\n",
        "        ndgrid = grid.clamp_(0, 255) \\\n",
        "                     .permute(1, 2, 0) \\\n",
        "                     .numpy() \\\n",
        "                     .astype(np.uint16)\n",
        "\n",
        "    return ndgrid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-xIcmFTYSmn"
      },
      "source": [
        "## 1. Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuxgRWpWYSGs"
      },
      "source": [
        "# Sample datasets\n",
        "class GenericImageDS(D.Dataset):\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_glob=\"*.jpg\",\n",
        "                 train=True,\n",
        "                 transform=None,\n",
        "                 min_image_dim=256):\n",
        "        self.root = root\n",
        "        self.image_glob = image_glob\n",
        "        self.train = train\n",
        "        self.min_image_dim = min_image_dim\n",
        "\n",
        "        image_regex = os.path.join(self.root, self.image_glob)\n",
        "        self.image_paths = glob.glob(image_regex)\n",
        "        if not len(self.image_paths):\n",
        "            raise ValueError(f\"No image found using {image_regex}\")\n",
        "\n",
        "        self.transform = transform\n",
        "        # Default set of transforms if none are provided\n",
        "        if self.transform is None:\n",
        "            self.transform = A.Compose([\n",
        "                A.Resize(self.min_image_dim, self.min_image_dim, 4, True, 1),\n",
        "                A.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), p=1),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "        logger.info(f\"Total samples: {len(self.image_paths)}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def download(urls, destination_dir, force=False):\n",
        "        destination_dir = Path(destination_dir)\n",
        "\n",
        "        # Check validity of arguments\n",
        "        if not destination_dir.is_dir():\n",
        "            raise ValueError(\"Provide destination_dir\")\n",
        "        if urls is None:\n",
        "            raise ValueError(\"Provide URL(s)\")\n",
        "\n",
        "        # Download & Extract\n",
        "        for url in urls:\n",
        "            fname = download_file(url, destination_dir)\n",
        "            extract_file(fname, destination_dir)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        image = np.asarray(Image.open(image_path))\n",
        "        image = self.transform(image=image)[\"image\"]\n",
        "        return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "\n",
        "# Test\n",
        "logger.setLevel(logging.DEBUG)\n",
        "# Write testing code here\n",
        "logger.setLevel(logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBxTMxZ9cs3K"
      },
      "source": [
        "## 2. Model Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63_8iSRzcs3L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwmGy6RSaYzx"
      },
      "source": [
        "## 3. Lightning Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpgZFC7KgI2N"
      },
      "source": [
        "# Sample data module\n",
        "class Houston18DataModule(pl.LightningDataModule):\n",
        "    \"\"\"\n",
        "    https://hyperspectral.ee.uh.edu/?page_id=1075\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size=4, patch_size=11):\n",
        "        super(Houston18DataModule, self).__init__()\n",
        "\n",
        "        self.patch_size   = patch_size\n",
        "        self.batch_size   = batch_size\n",
        "        self.rgb_bands    = (47, 31, 15)\n",
        "        self.label_values = [\n",
        "            \"Unclassified\",\n",
        "            \"Healthy grass\",\n",
        "            \"Stressed grass\",\n",
        "            \"Artificial turf\",\n",
        "            \"Evergreen trees\",\n",
        "            \"Deciduous trees\",\n",
        "            \"Bare earth\",\n",
        "            \"Water\",\n",
        "            \"Residential buildings\",\n",
        "            \"Non-residential buildings\",\n",
        "            \"Roads\",\n",
        "            \"Sidewalks\",\n",
        "            \"Crosswalks\",\n",
        "            \"Major thoroughfares\",\n",
        "            \"Highways\",\n",
        "            \"Railways\",\n",
        "            \"Paved parking lots\",\n",
        "            \"Unpaved parking lots\",\n",
        "            \"Cars\",\n",
        "            \"Trains\",\n",
        "            \"Stadium seats\",\n",
        "        ]\n",
        "        self.ignored_labels = [0]\n",
        "        self.palette = dict([\n",
        "            (0,  (0, 0, 0)),\n",
        "            (1,  (52, 209, 0)),\n",
        "            (2,  (143, 255, 0)),\n",
        "            (3,  (55, 153, 86)),\n",
        "            (4,  (34, 140, 0)),\n",
        "            (5,  (18, 70, 0)),\n",
        "            (6,  (155, 70, 32)),\n",
        "            (7,  (51, 254, 254)),\n",
        "            (8,  (255, 255, 255)),\n",
        "            (9,  (209, 185, 212)),\n",
        "            (10, (244, 0, 0)),\n",
        "            (11, (160, 147, 138)),\n",
        "            (12, (112, 110, 111)),\n",
        "            (13, (173, 0, 0)),\n",
        "            (14, (67, 0, 0)),\n",
        "            (15, (234, 158, 0)),\n",
        "            (16, (255, 255, 0)),\n",
        "            (17, (255, 216, 0)),\n",
        "            (18, (209, 0, 227)),\n",
        "            (19, (0, 0, 227)),\n",
        "            (20, (176, 194, 220)),\n",
        "        ])\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"\n",
        "        For operations that might write to disk or \n",
        "        that need to be done only from a single process in distributed settings.\n",
        "        DO NOT use to assign state as it is called from a single process.\n",
        "        \"\"\"\n",
        "        URL    = \"https://drive.google.com/u/0/uc?id=1Mf1nVX1SzaJUOwedJi9w5v2GRYGpxRiF\"\n",
        "        outdir = Path(\"./data/houston18/\")\n",
        "\n",
        "        # Safely create nested directory\n",
        "        outdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Download dataset\n",
        "        if not (outdir / \"H18data2_mat.mat\").exists():\n",
        "            gdown.download(URL, str(outdir / \"H18data2_mat.mat\"), quiet=False)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"For data operations on every GPU.\"\"\"\n",
        "        root  = Path(\"./data/houston18\")\n",
        "        data  = open_file(root / \"H18data2_mat.mat\")\n",
        "\n",
        "        if stage == \"fit\" or stage == \"test\" or None:\n",
        "            self.ds = GenericHSI(\n",
        "                img            = data['hsi_sub_zoom'],\n",
        "                gt             = data['gt'],\n",
        "                rgb_bands      = self.rgb_bands,\n",
        "                label_values   = self.label_values,\n",
        "                ignored_labels = self.ignored_labels,\n",
        "                palette        = self.palette,\n",
        "                patch_size     = self.patch_size\n",
        "            )\n",
        "            num_classes = len(self.label_values) - len(self.ignored_labels)\n",
        "\n",
        "            trainval_idx, _ = customClasswiseSplit(\n",
        "                self.ds.labels, \n",
        "                num_classes=num_classes,\n",
        "                num_samples=100,\n",
        "                ignore_indices=None\n",
        "            )\n",
        "\n",
        "            train_idx, valid_idx = train_test_split(\n",
        "                sorted(trainval_idx),\n",
        "                test_size=0.1,\n",
        "                stratify=np.array(self.ds.labels)[trainval_idx],\n",
        "                random_state=CONSTANTS['SEED']\n",
        "            )\n",
        "\n",
        "            test_idx, _  = customClasswiseSplit(\n",
        "                self.ds.labels,\n",
        "                num_classes=num_classes,\n",
        "                num_samples=2000,\n",
        "                ignore_indices=trainval_idx\n",
        "            )\n",
        "        \n",
        "            self.train_sampler = D.SubsetRandomSampler(train_idx)\n",
        "            self.valid_sampler = D.SubsetRandomSampler(valid_idx)\n",
        "            self.test_sampler  = D.SubsetRandomSampler(test_idx)\n",
        "        \n",
        "        if stage == \"inference\":\n",
        "            # If you need patches from the whole image\n",
        "            self.inference_ds = GenericHSIInference(\n",
        "                img            = data[\"hsi_sub_zoom\"],\n",
        "                patch_size     = self.patch_size,\n",
        "            )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return D.DataLoader(\n",
        "            self.ds, \n",
        "            batch_size=self.batch_size, \n",
        "            num_workers=2, \n",
        "            pin_memory=True, \n",
        "            sampler=self.train_sampler\n",
        "        )\n",
        "        \n",
        "    def val_dataloader(self):\n",
        "        return D.DataLoader(\n",
        "            self.ds, \n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=2, \n",
        "            pin_memory=True, \n",
        "            sampler=self.valid_sampler\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return D.DataLoader(\n",
        "            self.ds, \n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=2, \n",
        "            pin_memory=True, \n",
        "            sampler=self.test_sampler\n",
        "        )\n",
        "\n",
        "    def inference_dataloader(self, batch_size=4):\n",
        "        return D.DataLoader(\n",
        "            self.inference_ds,\n",
        "            batch_size=batch_size,\n",
        "            num_workers=2,\n",
        "            pin_memory=True,\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "    def teardown(self, stage=None):\n",
        "        \"\"\"Used to clean-up when run is finished\"\"\"\n",
        "        shutil.rmtree(\"./data/houston18\")\n",
        "    \n",
        "    def visualize(self):\n",
        "        ds = self.ds\n",
        "        data, label = ds[random.randint(0, len(ds))]\n",
        "        logger.debug(f\"\"\"data:  {data.min():.3f} to {data.max():.3f} \n",
        "                         with shape={data.shape}, dtype={data.dtype}\"\"\")\n",
        "        logger.debug(f\"\"\"label: {label.min()} to {label.max()} \n",
        "                         with shape={label.shape}, dtype={label.dtype}\"\"\")\n",
        " \n",
        "        # A single patch\n",
        "        img = display_dataset(data.squeeze().permute(1, 2, 0).numpy(), ds.rgb_bands)\n",
        "        plt.imshow(img)\n",
        "        plt.show()\n",
        "\n",
        "        # Full Image & Train GT\n",
        "        img = display_dataset(ds.data, ds.rgb_bands)\n",
        "        gt  = convert_to_color_(ds.label, ds.palette)\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(20, 20))\n",
        "        for a in ax:\n",
        "            a.axis('off')\n",
        "        ax[0].imshow(img)\n",
        "        ax[1].imshow(gt)\n",
        "        fig.tight_layout()\n",
        "        plt.show()\n",
        "        plot_colortable(ds.palette, \"Color table\")\n",
        "\n",
        "\n",
        "# Test\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "d = Houston18DataModule()\n",
        "d.prepare_data()\n",
        "d.setup(stage=\"fit\")\n",
        "d.visualize()\n",
        "d.teardown()\n",
        "\n",
        "del d\n",
        "logger.setLevel(logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57jkQ5F5aVs_"
      },
      "source": [
        "class FinalNet(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super(FinalNet, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def loss_function(self, preds, targets):\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "                  \n",
        "    def train_dataloader(self):\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def val_dataloader(self):\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, targets = batch\n",
        "        preds = self(inputs)\n",
        "        loss  = self.loss_function(preds, targets)\n",
        "\n",
        "        self.logger.experiment.log_metric('step_train_loss', loss)\n",
        "        return { 'loss': loss }\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
        "\n",
        "        self.logger.experiment.log_metric('epoch_train_loss', avg_loss)\n",
        "        \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        inputs, targets = batch\n",
        "        preds = self(inputs)\n",
        "        loss = self.loss_function(preds, targets)\n",
        "\n",
        "        self.logger.experiment.log_metric('step_val_loss', loss)\n",
        "        return { 'val_loss': loss }\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_val_loss = torch.stack([output['val_loss'] for output in outputs]).mean()\n",
        "\n",
        "        self.log('avg_val_loss', avg_val_loss)\n",
        "        self.logger.experiment.log_metric('epoch_val_loss', avg_val_loss)\n",
        "\n",
        "\n",
        "# Test\n",
        "logger.setLevel(logging.DEBUG)\n",
        "# Write testing code here\n",
        "logger.setLevel(logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdb6OMKha1N3"
      },
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvUXgrOha0op"
      },
      "source": [
        "hparams = {\n",
        "    'lr': 0.0001, \n",
        "    'batch_size': 4,\n",
        "    'max_epochs': 200,\n",
        "    'min_epochs': 10,\n",
        "    'check_val_every_n_epoch': 4,\n",
        "    'precision': 32,     # https://pytorch-lightning.readthedocs.io/en/latest/amp.html\n",
        "    'benchmark': True,\n",
        "    'deterministic': False,\n",
        "    'use_gpu': torch.cuda.is_available(),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-53FRnJxa3b8"
      },
      "source": [
        "# https://pytorch-lightning.readthedocs.io/en/latest/weights_loading.html?highlight=ModelCheckpoint\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    dirpath    = \"./checkpoints/\",\n",
        "    filename   = '{epoch:03d}__{avg_val_loss:.5f}',\n",
        "    save_top_k = 5,\n",
        "    monitor    = 'avg_val_loss',\n",
        "    mode       = 'min',\n",
        "    period     = 5\n",
        ")\n",
        "\n",
        "# https://pytorch-lightning.readthedocs.io/en/latest/early_stopping.html\n",
        "early_stop_callback = EarlyStopping(\n",
        "   monitor   = 'avg_val_loss',\n",
        "   min_delta = 1e-7,\n",
        "   patience  = 3,\n",
        "   verbose   = True,\n",
        "   mode      = 'min'\n",
        ")\n",
        "\n",
        "# https://docs.neptune.ai/api-reference/neptune/experiments/index.html#neptune.experiments.Experiment\n",
        "pl_logger = NeptuneLogger(\n",
        "    api_key         = CONSTANTS['API_TOKEN'],\n",
        "    project_name    = f\"\", # TODO\n",
        "    close_after_fit = True,\n",
        "    experiment_name = '',  # TODO\n",
        "    params          = hparams,\n",
        "    offline_model   = True,  # Comment to log into neptune.ai\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9yuf8HGa8E8"
      },
      "source": [
        "logger.setLevel(logging.INFO)\n",
        "pl.seed_everything(CONSTANTS['SEED'])\n",
        "\n",
        "dataset = Houston18DataModule(batch_size=hparams['batch_size'], \n",
        "                              patch_size=hparams['patch_size'])\n",
        "\n",
        "model   = FinalNet(hparams=hparams)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus                    = -1 if hparams['use_gpu'] else 0,\n",
        "    precision               = hparams['precision'],\n",
        "    gradient_clip_val       = hparams['gradient_clip_val'],\n",
        "    benchmark               = hparams['benchmark'],\n",
        "    deterministic           = hparams['deterministic'],\n",
        "    max_epochs              = hparams['max_epochs'],\n",
        "    min_epochs              = hparams['min_epochs'],\n",
        "    check_val_every_n_epoch = hparams['check_val_every_n_epoch'],\n",
        "    logger                  = pl_logger,\n",
        "    checkpoint_callback     = model_checkpoint,\n",
        "    callbacks               = [early_stop_callback],\n",
        ") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qnj1zATbRcz"
      },
      "source": [
        "# üêâ\n",
        "trainer.fit(model, dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nKV4JG7bVKc"
      },
      "source": [
        "# Log model summary\n",
        "for chunk in [x for x in str(model).split('\\n')]:\n",
        "    neptune_logger.experiment.log_text('model_summary', str(chunk))\n",
        "\n",
        "# Which GPUs where used?\n",
        "gpu_list = [f'{i}:{torch.cuda.get_device_name(i)}' \n",
        "            for i in range(torch.cuda.device_count())] \n",
        "neptune_logger.experiment.log_text('GPUs used', ', '.join(gpu_list))\n",
        "\n",
        "# Log best 3 model checkpoints to Neptune\n",
        "for k in model_checkpoint.best_k_models.keys():\n",
        "    model_name = 'checkpoints/' + k.split('/')[-1]\n",
        "    neptune_logger.experiment.log_artifact(k, model_name)\n",
        "\n",
        "# Save last path\n",
        "last_model_path = f\"checkpoints/last_model--epoch={trainer.current_epoch}.ckpt\"\n",
        "trainer.save_checkpoint(last_model_path)\n",
        "neptune_logger.experiment.log_artifact(\n",
        "    last_model_path, \n",
        "    'checkpoints/' + last_model_path.split('/')[-1]\n",
        ")\n",
        "\n",
        "# Log score of the best model checkpoint\n",
        "neptune_logger.experiment.set_property(\n",
        "    'best_model_score', \n",
        "    model_checkpoint.best_model_score.tolist()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0hfgUpGc8KY"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loFyeV9QdAMG"
      },
      "source": [
        "### Get weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPgTX3xoc9mH"
      },
      "source": [
        "# Get Neptune API token\n",
        "from getpass import getpass\n",
        "api_token = getpass(\"Enter Neptune.ai API token: \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBsssHUVc-_H"
      },
      "source": [
        "# Initialize Neptune project\n",
        "import neptune\n",
        "from neptune import Session\n",
        "\n",
        "session = Session.with_default_backend(api_token=api_token)\n",
        "project = session.get_project(f\"\") # TODO\n",
        "experiment = project.get_experiments(id='')[0] # TODO\n",
        "experiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Tl1389dDnu"
      },
      "source": [
        "# Download checkpoint from Neptune\n",
        "artifact_path   = 'epoch=133-avg_val_loss=1.06.ckpt'\n",
        "artifact_name   = artifact_path.split('/')[-1]\n",
        "checkpoint_dir  = os.path.join('checkpoints', 'downloads')\n",
        "checkpoint_path = os.path.join(checkpoint_dir, artifact_name)\n",
        "\n",
        "experiment.download_artifact(path=artifact_path, destination_dir=checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep_t3K3QdOf8"
      },
      "source": [
        "### Load weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK0SBDmudNma"
      },
      "source": [
        "model = FinalNet.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbQiVlludLp7"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r8XHFogdMKq"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}